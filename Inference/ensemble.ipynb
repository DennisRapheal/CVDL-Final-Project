{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59d4c3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005591,
     "end_time": "2025-05-25T12:17:39.025082",
     "exception": false,
     "start_time": "2025-05-25T12:17:39.019491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920c78d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:17:39.035307Z",
     "iopub.status.busy": "2025-05-25T12:17:39.035042Z",
     "iopub.status.idle": "2025-05-25T12:18:38.726711Z",
     "shell.execute_reply": "2025-05-25T12:18:38.725905Z"
    },
    "papermill": {
     "duration": 59.698496,
     "end_time": "2025-05-25T12:18:38.728180",
     "exception": false,
     "start_time": "2025-05-25T12:17:39.029684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 12:17:42.246372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748175462.436451      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748175462.489907      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:107: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functools import partial\n",
    "from albumentations import (Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, CenterCrop, \n",
    "                            HorizontalFlip, VerticalFlip, Rotate, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e6671b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.738960Z",
     "iopub.status.busy": "2025-05-25T12:18:38.738669Z",
     "iopub.status.idle": "2025-05-25T12:18:38.764697Z",
     "shell.execute_reply": "2025-05-25T12:18:38.764113Z"
    },
    "papermill": {
     "duration": 0.032796,
     "end_time": "2025-05-25T12:18:38.765912",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.733116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/cassava-leaf-disease-classification/\"\n",
    "image_path = path+\"test_images/\"\n",
    "\n",
    "IMAGE_SIZE = (512,512)\n",
    "submission_df = pd.DataFrame(columns=(\"image_id\",\"label\"))\n",
    "submission_df[\"image_id\"] = os.listdir(image_path)\n",
    "submission_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e70571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.776211Z",
     "iopub.status.busy": "2025-05-25T12:18:38.775977Z",
     "iopub.status.idle": "2025-05-25T12:18:38.780525Z",
     "shell.execute_reply": "2025-05-25T12:18:38.779975Z"
    },
    "papermill": {
     "duration": 0.010748,
     "end_time": "2025-05-25T12:18:38.781546",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.770798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "used_models_pytorch = {\"noefficientnet\": [f'../input/efficientnet-mixup-512/efficientnetv2_rw_s_fold{fold}_best.pth' for fold in [0,1,2,3,4]],\n",
    "                        # \"convnext\":[f'../input/convnext-mixup/convnext_tiny_fold{fold}_best.pth' for fold in [0,1,2,3,4]],\n",
    "                        \"newconvnext\":[f'../input/convnextv2-small/convnextv2_small_cassava_8903.pth'],\n",
    "                        # \"noresnext_old\": [f'../input/resnext50/resnext50_32x4d_fold{fold}_best.pth' for fold in [0,1,2,3,4]],\n",
    "                        \"resnext_new\": [f'../input/testrestnet/resnext50_32x4d_fold{fold}_best.pth' for fold in [0,1,2,3,4]],\n",
    "                        \"tf_efficientnetv2_xl\":[f\"../input/5fold-effxl-2/eff_fold{fold}/home/ccwang/dennis/dennislin0906/cvdl-final/5fold/tf_efficientnetv2_xl_fold{fold}_best.pth\" for fold in [0,1,2,3,4]],\n",
    "                        \"tf_efficientnetv2_l_in21k\":[f\"../input/5fold-eff-l-v2/eff_fold{fold}/home/ccwang/dennis/dennislin0906/cvdl-final/v2_l_5fold/tf_efficientnetv2_l_fold{fold}_best.pth\" for fold in [0,1,2,3,4]],\n",
    "                        \"swintransformer\":[\"../input/swintransformer/swin_base_cassava_8857.pth\"]}\n",
    "used_models_keras = {\"mobilenet\": \"../input/mobilenet/1426ba4824f415259798eb0bd7379e39cb679725\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e312fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.791925Z",
     "iopub.status.busy": "2025-05-25T12:18:38.791353Z",
     "iopub.status.idle": "2025-05-25T12:18:38.801817Z",
     "shell.execute_reply": "2025-05-25T12:18:38.801259Z"
    },
    "papermill": {
     "duration": 0.016705,
     "end_time": "2025-05-25T12:18:38.802881",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.786176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvnextModel(nn.Module):\n",
    "    def __init__(self, model_name='convnext_tiny', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        # print(self.model)\n",
    "        n_features = self.model.head.fc.in_features\n",
    "        self.model.head.fc = nn.Linear(n_features, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"convnext\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_convnext = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_convnext[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_convnext['image_path_id'] = image_path + predictions_convnext['image_id'].astype(str)\n",
    "\n",
    "    model = ConvnextModel('convnext_tiny', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"convnext\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_convnext, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_convnext['convnext'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_convnext = predictions_convnext.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54ac4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.812769Z",
     "iopub.status.busy": "2025-05-25T12:18:38.812551Z",
     "iopub.status.idle": "2025-05-25T12:18:38.816575Z",
     "shell.execute_reply": "2025-05-25T12:18:38.815883Z"
    },
    "papermill": {
     "duration": 0.01025,
     "end_time": "2025-05-25T12:18:38.817602",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.807352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class coatnet(nn.Module):\n",
    "#     def __init__(self, model_name='coatnet_0_rw_224.sw_in1k', pretrained=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "#         self.model.reset_classifier(num_classes=5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, df, transform=None):\n",
    "#         self.df = df\n",
    "#         self.file_names = df['image_path_id'].values\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         file_name = self.file_names[idx]\n",
    "#         image = cv2.imread(file_name)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image)\n",
    "#             image = augmented['image']\n",
    "#         return image\n",
    "\n",
    "# if \"coatnet\" in used_models_pytorch:\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     def get_transforms():\n",
    "#         return Compose([Resize(224, 224),\n",
    "#                         Transpose(p=0.5),\n",
    "#                         HorizontalFlip(p=0.5),\n",
    "#                         VerticalFlip(p=0.5),\n",
    "#                         Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#                         ToTensorV2()])\n",
    "\n",
    "#     def inference(model, states, test_loader, device):\n",
    "#         model.to(device)\n",
    "\n",
    "#         probabilities = []\n",
    "#         for i, (images) in enumerate(test_loader):\n",
    "#             images = images.to(device)\n",
    "#             avg_preds = []\n",
    "#             for state in states:\n",
    "#                 model.load_state_dict(state['model'])\n",
    "#                 model.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     y_preds = model(images)\n",
    "#                 avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "#             avg_preds = np.mean(avg_preds, axis=0)\n",
    "#             probabilities.append(avg_preds)\n",
    "#         return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "#     predictions_coatnet = pd.DataFrame(columns=(\"image_id\",))\n",
    "#     predictions_coatnet[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "#     predictions_coatnet['image_path_id'] = image_path + predictions_coatnet['image_id'].astype(str)\n",
    "\n",
    "#     model = coatnet('coatnet_0_rw_224.sw_in1k', pretrained=False)\n",
    "#     states = [torch.load(f) for f in used_models_pytorch[\"coatnet\"]]\n",
    "\n",
    "#     test_dataset = TestDataset(predictions_coatnet, transform=get_transforms())\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "#     predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "#     predictions_coatnet['coatnet'] = [np.squeeze(p) for p in predictions]\n",
    "#     predictions_coatnet = predictions_coatnet.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     try:\n",
    "#         del(model)\n",
    "#         del(states)\n",
    "#     except:\n",
    "#         pass\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d426c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.827362Z",
     "iopub.status.busy": "2025-05-25T12:18:38.827178Z",
     "iopub.status.idle": "2025-05-25T12:18:38.837950Z",
     "shell.execute_reply": "2025-05-25T12:18:38.837482Z"
    },
    "papermill": {
     "duration": 0.01698,
     "end_time": "2025-05-25T12:18:38.839012",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.822032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EfficientNetV2(nn.Module):\n",
    "    def __init__(self, model_name='efficientnetv2_rw_s', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        # 根據模型類型選擇 head\n",
    "        if hasattr(self.model, 'classifier'):  # e.g., efficientnetv2\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, 5)\n",
    "        elif hasattr(self.model.head, 'fc'):  # e.g., convnext\n",
    "            n_features = self.model.head.fc.in_features\n",
    "            self.model.head.fc = nn.Linear(n_features, 5)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unsupported model structure for head replacement.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"efficientnet\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([CenterCrop(512,512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_efficient = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_efficient[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_efficient['image_path_id'] = image_path + predictions_efficient['image_id'].astype(str)\n",
    "\n",
    "    model = EfficientNetV2('efficientnetv2_rw_s', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"efficientnet\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_efficient, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_efficient['efficientnet'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_efficient = predictions_efficient.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61daf71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.848763Z",
     "iopub.status.busy": "2025-05-25T12:18:38.848573Z",
     "iopub.status.idle": "2025-05-25T12:18:38.854254Z",
     "shell.execute_reply": "2025-05-25T12:18:38.853751Z"
    },
    "papermill": {
     "duration": 0.011671,
     "end_time": "2025-05-25T12:18:38.855269",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.843598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# model initialization\n",
    "# ====================================================\n",
    "\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d.a1h_in1k', pretrained=False):\n",
    "        super().__init__()\n",
    "        # self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, 5)\n",
    "        # # 根據模型類型選擇 head\n",
    "        # if hasattr(self.model, 'classifier'):  # e.g., efficientnetv2\n",
    "        #     n_features = self.model.classifier.in_features\n",
    "        #     self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "        # elif hasattr(self.model.head, 'fc'):  # e.g., convnext\n",
    "        #     n_features = self.model.head.fc.in_features\n",
    "        #     self.model.head.fc = nn.Linear(n_features, CFG.target_size)\n",
    "        # else:\n",
    "        #     raise NotImplementedError(\"Unsupported model structure for head replacement.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb068d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.865091Z",
     "iopub.status.busy": "2025-05-25T12:18:38.864908Z",
     "iopub.status.idle": "2025-05-25T12:18:38.871876Z",
     "shell.execute_reply": "2025-05-25T12:18:38.871354Z"
    },
    "papermill": {
     "duration": 0.012989,
     "end_time": "2025-05-25T12:18:38.872833",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.859844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"resnext_old\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_resnext_old = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_resnext_old[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_resnext_old['image_path_id'] = image_path + predictions_resnext_old['image_id'].astype(str)\n",
    "\n",
    "    model = CustomResNext('resnext50_32x4d', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"resnext_old\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_resnext_old, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_resnext_old['resnext_old'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_resnext_old = predictions_resnext_old.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75d09d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:38.882534Z",
     "iopub.status.busy": "2025-05-25T12:18:38.882323Z",
     "iopub.status.idle": "2025-05-25T12:18:44.843104Z",
     "shell.execute_reply": "2025-05-25T12:18:44.842411Z"
    },
    "papermill": {
     "duration": 5.96736,
     "end_time": "2025-05-25T12:18:44.844605",
     "exception": false,
     "start_time": "2025-05-25T12:18:38.877245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/99005018.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  states = [torch.load(f) for f in used_models_pytorch[\"resnext_new\"]]\n"
     ]
    }
   ],
   "source": [
    "if \"resnext_new\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_resnext_new = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_resnext_new[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_resnext_new['image_path_id'] = image_path + predictions_resnext_new['image_id'].astype(str)\n",
    "\n",
    "    model = CustomResNext('resnext50_32x4d', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"resnext_new\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_resnext_new, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_resnext_new['resnext_new'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_resnext_new = predictions_resnext_new.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd16ce72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:44.855784Z",
     "iopub.status.busy": "2025-05-25T12:18:44.855467Z",
     "iopub.status.idle": "2025-05-25T12:18:44.862584Z",
     "shell.execute_reply": "2025-05-25T12:18:44.861847Z"
    },
    "papermill": {
     "duration": 0.013904,
     "end_time": "2025-05-25T12:18:44.863794",
     "exception": false,
     "start_time": "2025-05-25T12:18:44.849890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        # EfficientNet-B4，僅取最後一層 feature map（stride=32）\n",
    "        self.eff = timm.create_model(\n",
    "            \"tf_efficientnetv2_xl\",\n",
    "            pretrained=pretrained,\n",
    "            features_only=True,\n",
    "            out_indices=[-1],\n",
    "        )\n",
    "        eff_ch = self.eff.feature_info.channels()[-1]  # 1792\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(eff_ch, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.eff(x)[0]  # (B, 1792, H/32, W/32)\n",
    "        return self.classifier(feats)\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6312f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:44.874054Z",
     "iopub.status.busy": "2025-05-25T12:18:44.873424Z",
     "iopub.status.idle": "2025-05-25T12:18:44.877224Z",
     "shell.execute_reply": "2025-05-25T12:18:44.876586Z"
    },
    "papermill": {
     "duration": 0.009771,
     "end_time": "2025-05-25T12:18:44.878234",
     "exception": false,
     "start_time": "2025-05-25T12:18:44.868463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _clean_state_dict(state):\n",
    "    if next(iter(state)).startswith(\"module.\"):\n",
    "        return {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c04bc0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:18:44.888301Z",
     "iopub.status.busy": "2025-05-25T12:18:44.888097Z",
     "iopub.status.idle": "2025-05-25T12:19:12.010479Z",
     "shell.execute_reply": "2025-05-25T12:19:12.009494Z"
    },
    "papermill": {
     "duration": 27.129469,
     "end_time": "2025-05-25T12:19:12.012234",
     "exception": false,
     "start_time": "2025-05-25T12:18:44.882765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/157920284.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(state, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "if \"tf_efficientnetv2_xl\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                ckpt = torch.load(state, map_location=\"cpu\")\n",
    "                model.load_state_dict(_clean_state_dict(ckpt[\"model\"]), strict=False)\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    predictions_test = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_test[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_test['image_path_id'] = image_path + predictions_test['image_id'].astype(str)\n",
    "\n",
    "    model = EfficientNetClassifier(pretrained=False)\n",
    "    states = [f for f in used_models_pytorch[\"tf_efficientnetv2_xl\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_test, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_test['tf_efficientnetv2_xl'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_test = predictions_test.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2c01cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:12.023079Z",
     "iopub.status.busy": "2025-05-25T12:19:12.022827Z",
     "iopub.status.idle": "2025-05-25T12:19:16.428216Z",
     "shell.execute_reply": "2025-05-25T12:19:16.427492Z"
    },
    "papermill": {
     "duration": 4.412494,
     "end_time": "2025-05-25T12:19:16.429841",
     "exception": false,
     "start_time": "2025-05-25T12:19:12.017347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/93820309.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(state, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"swintransformer\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(384, 384),\n",
    "                        # Transpose(p=0.5),\n",
    "                        # HorizontalFlip(p=0.5),\n",
    "                        # VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                ckpt = torch.load(state, map_location=\"cpu\")\n",
    "                model.load_state_dict(_clean_state_dict(ckpt), strict=False)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_swintransformer = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_swintransformer[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_swintransformer['image_path_id'] = image_path + predictions_swintransformer['image_id'].astype(str)\n",
    "\n",
    "    model = timm.create_model(\"swin_base_patch4_window12_384\", pretrained=False, num_classes=5)\n",
    "    states = [f for f in used_models_pytorch[\"swintransformer\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_swintransformer, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_swintransformer['swintransformer'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_swintransformer = predictions_swintransformer.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28575e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:16.441744Z",
     "iopub.status.busy": "2025-05-25T12:19:16.441056Z",
     "iopub.status.idle": "2025-05-25T12:19:18.513344Z",
     "shell.execute_reply": "2025-05-25T12:19:18.512329Z"
    },
    "papermill": {
     "duration": 2.079555,
     "end_time": "2025-05-25T12:19:18.514863",
     "exception": false,
     "start_time": "2025-05-25T12:19:16.435308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3125122570.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(state, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"newconvnext\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                ckpt = torch.load(state, map_location=\"cpu\")\n",
    "                model.load_state_dict(_clean_state_dict(ckpt), strict=False)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_newconvnext = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_newconvnext[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_newconvnext['image_path_id'] = image_path + predictions_newconvnext['image_id'].astype(str)\n",
    "\n",
    "    \n",
    "    model = timm.create_model(\"convnextv2_tiny\", pretrained=False, num_classes=5)\n",
    "    states = [f for f in used_models_pytorch[\"newconvnext\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_newconvnext, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_newconvnext['newconvnext'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_newconvnext = predictions_newconvnext.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "113becb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:18.525749Z",
     "iopub.status.busy": "2025-05-25T12:19:18.525507Z",
     "iopub.status.idle": "2025-05-25T12:19:34.953705Z",
     "shell.execute_reply": "2025-05-25T12:19:34.952729Z"
    },
    "papermill": {
     "duration": 16.435288,
     "end_time": "2025-05-25T12:19:34.955282",
     "exception": false,
     "start_time": "2025-05-25T12:19:18.519994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnetv2_l_in21k to current tf_efficientnetv2_l.in21k.\n",
      "  model = create_fn(\n",
      "/tmp/ipykernel_19/2487358599.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(state, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3.0, eps=1e-6, trainable=True):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        if trainable:\n",
    "            self.p = nn.Parameter(torch.ones(1) * p)  # 可訓練\n",
    "        else:\n",
    "            self.p = torch.tensor([p])                # 固定常數\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, H, W)\n",
    "        return F.adaptive_avg_pool2d(x.clamp(min=self.eps).pow(self.p), 1).pow(1.0 / self.p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n",
    "\n",
    "class EfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        self.eff = timm.create_model(\n",
    "            \"tf_efficientnetv2_l_in21k\",\n",
    "            pretrained=pretrained,\n",
    "            drop_path_rate=0.2,\n",
    "            features_only=True,\n",
    "            out_indices=[-1],\n",
    "        )\n",
    "        eff_ch = self.eff.feature_info.channels()[-1]  # 1792\n",
    "\n",
    "        self.pool = GeM(p=3.0, trainable=True)          # GeM global pooling\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(eff_ch, 512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.eff(x)[0]\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.head(x)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = cv2.imread(file_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "\n",
    "if \"tf_efficientnetv2_l_in21k\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512,512),\n",
    "                        Transpose(p=0.5),\n",
    "                        HorizontalFlip(p=0.5),\n",
    "                        VerticalFlip(p=0.5),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                ckpt = torch.load(state, map_location=\"cpu\")\n",
    "                model.load_state_dict(_clean_state_dict(ckpt[\"model\"]), strict=False)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_tf_efficientnetv2_l_in21k = pd.DataFrame(columns=(\"image_id\",))\n",
    "    predictions_tf_efficientnetv2_l_in21k[\"image_id\"] = submission_df[\"image_id\"].values\n",
    "    predictions_tf_efficientnetv2_l_in21k['image_path_id'] = image_path + predictions_tf_efficientnetv2_l_in21k['image_id'].astype(str)\n",
    "\n",
    "    model = EfficientNetClassifier(pretrained=False)\n",
    "    states = [f for f in used_models_pytorch[\"tf_efficientnetv2_l_in21k\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_tf_efficientnetv2_l_in21k, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_tf_efficientnetv2_l_in21k['tf_efficientnetv2_l_in21k'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_tf_efficientnetv2_l_in21k = predictions_tf_efficientnetv2_l_in21k.drop([\"image_path_id\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df6135a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:34.966818Z",
     "iopub.status.busy": "2025-05-25T12:19:34.966547Z",
     "iopub.status.idle": "2025-05-25T12:19:36.122487Z",
     "shell.execute_reply": "2025-05-25T12:19:36.121677Z"
    },
    "papermill": {
     "duration": 1.163082,
     "end_time": "2025-05-25T12:19:36.123883",
     "exception": false,
     "start_time": "2025-05-25T12:19:34.960801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def build_mobilenet3(img_size=(224, 224), weights=\"../input/mobilenet/1426ba4824f415259798eb0bd7379e39cb679725\"):\n",
    "    # 載入 Hub 模型\n",
    "    classifier = hub.KerasLayer(\n",
    "        weights, \n",
    "        input_shape=(img_size[0], img_size[1], 3),\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310d9f0",
   "metadata": {
    "papermill": {
     "duration": 0.00474,
     "end_time": "2025-05-25T12:19:36.133794",
     "exception": false,
     "start_time": "2025-05-25T12:19:36.129054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a510f",
   "metadata": {
    "papermill": {
     "duration": 0.004725,
     "end_time": "2025-05-25T12:19:36.143483",
     "exception": false,
     "start_time": "2025-05-25T12:19:36.138758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6191976b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:36.154226Z",
     "iopub.status.busy": "2025-05-25T12:19:36.153987Z",
     "iopub.status.idle": "2025-05-25T12:19:43.290265Z",
     "shell.execute_reply": "2025-05-25T12:19:43.289361Z"
    },
    "papermill": {
     "duration": 7.143461,
     "end_time": "2025-05-25T12:19:43.291591",
     "exception": false,
     "start_time": "2025-05-25T12:19:36.148130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748175577.416893      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14985 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]I0000 00:00:1748175582.247171     153 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "def image_augmentations(image):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if p_spatial > 0.75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    if p_rotate > 0.75:\n",
    "        image = tf.image.rot90(image, k = 3)\n",
    "    elif p_rotate > 0.5:\n",
    "        image = tf.image.rot90(image, k = 2)\n",
    "    elif p_rotate > 0.25:\n",
    "        image = tf.image.rot90(image, k = 1)\n",
    "\n",
    "    image = tf.image.resize(image, size = IMAGE_SIZE)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    \n",
    "    return image\n",
    "\n",
    "def read_preprocess_file(img_path, normalize=False):\n",
    "    image = Image.open(img_path)\n",
    "    if normalize:\n",
    "        img_scaled = np.array(image)/ 255.0\n",
    "    else:\n",
    "        img_scaled = np.array(image)\n",
    "    img_scaled = img_scaled.astype(np.float32)\n",
    "    return (image.size[0], image.size[1]), img_scaled\n",
    "\n",
    "def create_image_tiles(origin_dim, processed_img):\n",
    "    crop_size = 512\n",
    "    img_list = []\n",
    "    # Cut image into 4 overlapping patches\n",
    "    for x in [0, origin_dim[1] - crop_size]:\n",
    "        for y in [0, origin_dim[0] - crop_size]:\n",
    "            img_list.append(processed_img[x:x+crop_size , y:y+crop_size,:])\n",
    "    # Keep one additional center cropped image \n",
    "    img_list.append(cv2.resize(processed_img[:, 100:700 ,:], dsize=(crop_size, crop_size)))\n",
    "    return np.array(img_list)\n",
    "\n",
    "def augment_tiles_light(tiles, ttas=2):\n",
    "  # Copy central croped image to have same ratio to augmented images\n",
    "  holdout = np.broadcast_to(tiles[-1,:,:,:],(ttas,) + tiles.shape[1:])\n",
    "  augmented_batch = tf.map_fn(lambda x: image_augmentations(x), tf.concat(\n",
    "      [tiles[:-1,:,:,:] for _ in range(ttas)], axis=0))\n",
    "  return tf.concat([augmented_batch, holdout], axis=0)\n",
    "\n",
    "def cut_crop_image(processed_img):\n",
    "    image = tf.image.central_crop(processed_img, 0.8)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "# CropNet class 6 (unknown) is distributed evenly over all 5 classes to match problem setting\n",
    "def distribute_unknown(propabilities):\n",
    "    return propabilities[:,:-1] + np.expand_dims(propabilities[:,-1]/5, 1)\n",
    "\n",
    "def multi_predict_tfhublayer(img_path, modelinstance):\n",
    "    img = cut_crop_image(read_preprocess_file(img_path, True)[1])\n",
    "    yhat = modelinstance(img)\n",
    "    return np.mean(distribute_unknown(yhat), axis=0)\n",
    "\n",
    "def multi_predict_keras(img_path, modelinstance, *args):\n",
    "    augmented_batch = augment_tiles_light(create_image_tiles(\n",
    "        *read_preprocess_file(img_path)))\n",
    "    Yhat = modelinstance(augmented_batch)\n",
    "    return np.mean(Yhat, axis=0)\n",
    "\n",
    "def predict_and_vote(image_list, modelinstances, onlykeras):\n",
    "    predictions = [] \n",
    "    with tqdm(total=len(image_list)) as process_bar:       \n",
    "      for img_path in image_list:\n",
    "        process_bar.update(1)  \n",
    "        Yhats = np.vstack([func(img_path, modelinstance) for func, modelinstance in modelinstances])\n",
    "        if onlykeras:\n",
    "            predictions.append(np.argmax(np.sum(Yhats, axis=0)))\n",
    "        else:\n",
    "            predictions.append(Yhats)    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "inference_models = []\n",
    "\n",
    "if \"mobilenet\" in used_models_keras:\n",
    "    model_mobilenet = build_mobilenet3(weights=used_models_keras[\"mobilenet\"])\n",
    "    inference_models.append((multi_predict_tfhublayer, model_mobilenet))\n",
    "    \n",
    "# if \"efficientnetb4\" in used_models_keras:\n",
    "#     model_efficientnetb4 =  keras.models.load_model(used_models_keras[\"efficientnetb4\"], compile=False)\n",
    "#     inference_models.append((multi_predict_keras, model_efficientnetb4))\n",
    "    \n",
    "# if \"efficientnetb5\" in used_models_keras:\n",
    "#     model_efficientnetb5 =  keras.models.load_model(used_models_keras[\"efficientnetb5\"])\n",
    "#     inference_models.append((multi_predict_keras, model_efficientnetb5))\n",
    "onlykeras=False\n",
    "submission_df[\"label\"] = predict_and_vote([image_path+id for id in submission_df[\"image_id\"].values], inference_models, onlykeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6565fd4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:43.302613Z",
     "iopub.status.busy": "2025-05-25T12:19:43.302362Z",
     "iopub.status.idle": "2025-05-25T12:19:44.216238Z",
     "shell.execute_reply": "2025-05-25T12:19:44.215484Z"
    },
    "papermill": {
     "duration": 0.920515,
     "end_time": "2025-05-25T12:19:44.217422",
     "exception": false,
     "start_time": "2025-05-25T12:19:43.296907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "try:\n",
    "    del inference_models[:]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107137f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:44.229056Z",
     "iopub.status.busy": "2025-05-25T12:19:44.228808Z",
     "iopub.status.idle": "2025-05-25T12:19:44.248002Z",
     "shell.execute_reply": "2025-05-25T12:19:44.247415Z"
    },
    "papermill": {
     "duration": 0.026252,
     "end_time": "2025-05-25T12:19:44.249048",
     "exception": false,
     "start_time": "2025-05-25T12:19:44.222796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(list(used_models_keras.keys())) <= 1:\n",
    "    submission_df.loc[:,list(used_models_keras)[0]] = submission_df[\"label\"].explode()\n",
    "else:\n",
    "    tmp = (submission_df['label'].transform([lambda x:x[0], lambda x:x[1]]).set_axis(list(used_models_keras.keys()), axis=1, inplace=False))\n",
    "    submission_df = submission_df.merge(tmp, right_index=True, left_index=True)\n",
    "    \n",
    "submission_df[\"label\"] = 0\n",
    "\n",
    "# if \"coatnet\" in used_models_pytorch:\n",
    "#     submission_df = submission_df.merge(predictions_coatnet, on=\"image_id\")\n",
    "\n",
    "if \"convnext\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_convnext, on=\"image_id\")\n",
    "\n",
    "if \"swintransformer\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_swintransformer, on=\"image_id\")\n",
    "if \"efficientnet\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_efficient, on=\"image_id\")\n",
    "if \"tf_efficientnetv2_xl\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_test, on=\"image_id\")\n",
    "if \"tf_efficientnetv2_l_in21k\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_tf_efficientnetv2_l_in21k, on=\"image_id\")\n",
    "if \"resnext_old\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_resnext_old, on=\"image_id\")\n",
    "if \"resnext_new\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_resnext_new, on=\"image_id\")\n",
    "if \"newconvnext\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_newconvnext, on=\"image_id\")\n",
    "# if \"efficientnetb3\" in used_models_pytorch:\n",
    "#     submission_df = submission_df.merge(predictions_cutmix, on=\"image_id\")\n",
    "    \n",
    "# if \"vit2020\" in used_models_pytorch:\n",
    "#     submission_df = submission_df.merge(predictions_vit, on=\"image_id\")\n",
    "    \n",
    "# if \"vit2019\" in used_models_pytorch:\n",
    "#     submission_df = submission_df.merge(predictions_vit2019, on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "401480a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:44.260243Z",
     "iopub.status.busy": "2025-05-25T12:19:44.259991Z",
     "iopub.status.idle": "2025-05-25T12:19:44.269499Z",
     "shell.execute_reply": "2025-05-25T12:19:44.268932Z"
    },
    "papermill": {
     "duration": 0.016314,
     "end_time": "2025-05-25T12:19:44.270571",
     "exception": false,
     "start_time": "2025-05-25T12:19:44.254257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_mean = True\n",
    "if stacked_mean:\n",
    "    submission_df[\"stage_1\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"swintransformer\"], row[\"newconvnext\"])], axis=1)\n",
    "    submission_df[\"stage_2\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"stage_1\"], row[\"resnext_new\"], row[\"tf_efficientnetv2_xl\"])], axis=1)\n",
    "    submission_df[\"stage_3\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"stage_2\"], row[\"tf_efficientnetv2_l_in21k\"])], axis=1)\n",
    "    # submission_df[\"stage_1\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"efficientnet\"],row[\"tf_efficientnetv2_xl\"])], axis=1)\n",
    "    # submission_df[\"stage_3\"] = submission_df.apply(lambda row: [np.mean(e) for e in zip(row[\"tf_efficientnetv2_l_in21k\"], row[\"stage_2\"])], axis=1)\n",
    "    submission_df[\"label\"] = submission_df.apply(lambda row: np.argmax(\n",
    "        [np.sum(e) for e in zip(row[\"mobilenet\"],row[\"stage_3\"])]), axis=1)\n",
    "else:\n",
    "    submission_df[\"label\"] = submission_df.apply(lambda row: np.argmax(\n",
    "        [np.sum(e) for e in zip(*[row[m] for m in list(used_models_pytorch.keys())+list(used_models_keras.keys())])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "924a6100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:44.281741Z",
     "iopub.status.busy": "2025-05-25T12:19:44.281501Z",
     "iopub.status.idle": "2025-05-25T12:19:44.302049Z",
     "shell.execute_reply": "2025-05-25T12:19:44.301376Z"
    },
    "papermill": {
     "duration": 0.02738,
     "end_time": "2025-05-25T12:19:44.303115",
     "exception": false,
     "start_time": "2025-05-25T12:19:44.275735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>mobilenet</th>\n",
       "      <th>swintransformer</th>\n",
       "      <th>tf_efficientnetv2_xl</th>\n",
       "      <th>tf_efficientnetv2_l_in21k</th>\n",
       "      <th>resnext_new</th>\n",
       "      <th>newconvnext</th>\n",
       "      <th>stage_1</th>\n",
       "      <th>stage_2</th>\n",
       "      <th>stage_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0037992653, 0.0037114928, 0.87805223, 0.005...</td>\n",
       "      <td>[2.7445092e-05, 0.0001162478, 0.01800231, 7.43...</td>\n",
       "      <td>[0.006624048, 0.059600253, 0.17610297, 0.02277...</td>\n",
       "      <td>[0.05921451, 0.07604618, 0.2396855, 0.03580349...</td>\n",
       "      <td>[0.023723358, 0.0414746, 0.42054933, 0.0440246...</td>\n",
       "      <td>[0.0041348706, 0.0070461934, 0.20124628, 0.047...</td>\n",
       "      <td>[0.0020811579, 0.0035812205, 0.1096243, 0.0238...</td>\n",
       "      <td>[0.010809521, 0.034885358, 0.23542555, 0.03021...</td>\n",
       "      <td>[0.035012014, 0.055465773, 0.23755553, 0.03301...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label                                          mobilenet  \\\n",
       "0  2216849948.jpg      2  [0.0037992653, 0.0037114928, 0.87805223, 0.005...   \n",
       "\n",
       "                                     swintransformer  \\\n",
       "0  [2.7445092e-05, 0.0001162478, 0.01800231, 7.43...   \n",
       "\n",
       "                                tf_efficientnetv2_xl  \\\n",
       "0  [0.006624048, 0.059600253, 0.17610297, 0.02277...   \n",
       "\n",
       "                           tf_efficientnetv2_l_in21k  \\\n",
       "0  [0.05921451, 0.07604618, 0.2396855, 0.03580349...   \n",
       "\n",
       "                                         resnext_new  \\\n",
       "0  [0.023723358, 0.0414746, 0.42054933, 0.0440246...   \n",
       "\n",
       "                                         newconvnext  \\\n",
       "0  [0.0041348706, 0.0070461934, 0.20124628, 0.047...   \n",
       "\n",
       "                                             stage_1  \\\n",
       "0  [0.0020811579, 0.0035812205, 0.1096243, 0.0238...   \n",
       "\n",
       "                                             stage_2  \\\n",
       "0  [0.010809521, 0.034885358, 0.23542555, 0.03021...   \n",
       "\n",
       "                                             stage_3  \n",
       "0  [0.035012014, 0.055465773, 0.23755553, 0.03301...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d161380c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T12:19:44.314620Z",
     "iopub.status.busy": "2025-05-25T12:19:44.314374Z",
     "iopub.status.idle": "2025-05-25T12:19:44.501067Z",
     "shell.execute_reply": "2025-05-25T12:19:44.500251Z"
    },
    "papermill": {
     "duration": 0.19388,
     "end_time": "2025-05-25T12:19:44.502390",
     "exception": false,
     "start_time": "2025-05-25T12:19:44.308510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id,label\r\n",
      "2216849948.jpg,2\r\n"
     ]
    }
   ],
   "source": [
    "submission_df[[\"image_id\",\"label\"]].to_csv(\"submission.csv\", index=False)\n",
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1718836,
     "sourceId": 13836,
     "sourceType": "competition"
    },
    {
     "datasetId": 686792,
     "sourceId": 2660070,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1027206,
     "sourceId": 3951115,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7374762,
     "sourceId": 11747597,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7379494,
     "sourceId": 11754731,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7381381,
     "sourceId": 11758048,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7382056,
     "sourceId": 11759128,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7385731,
     "sourceId": 11764642,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7389534,
     "sourceId": 11770324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7392753,
     "sourceId": 11775075,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7393630,
     "sourceId": 11776592,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7398358,
     "sourceId": 11783701,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7421797,
     "sourceId": 11816272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7431260,
     "sourceId": 11829245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7441596,
     "sourceId": 11844012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7443874,
     "sourceId": 11847252,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7452673,
     "sourceId": 11877277,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7483267,
     "sourceId": 11904319,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7493223,
     "sourceId": 11919154,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7506157,
     "sourceId": 11939270,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7507219,
     "sourceId": 11941695,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7508290,
     "sourceId": 11943504,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 55,
     "modelInstanceId": 646,
     "sourceId": 779,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.283203,
   "end_time": "2025-05-25T12:19:48.163113",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T12:17:34.879910",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
